{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81cb8dd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-12T06:26:13.538588Z",
     "start_time": "2022-04-12T06:26:12.872398Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.dirname(os.path.abspath('.')))\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from copy import deepcopy\n",
    "import random\n",
    "\n",
    "import torch_pruning as tp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08f068c",
   "metadata": {},
   "source": [
    "# 搞个复杂的网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ea959ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-12T11:27:24.571517Z",
     "start_time": "2022-04-12T11:27:24.562917Z"
    }
   },
   "outputs": [],
   "source": [
    "class DeepFCN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(DeepFCN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 256)\n",
    "        self.add_module('first_relu', nn.ReLU())\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(256,64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc3 = nn.ModuleList(\n",
    "            [nn.Sequential(\n",
    "            nn.Linear(64,64),\n",
    "            nn.ReLU()) for i in range(3)\n",
    "            ]\n",
    "        )\n",
    "        self.fc4 = nn.ModuleDict({\n",
    "            'fc4-1': nn.Linear(64,32),\n",
    "            'relu': nn.ReLU()\n",
    "        })\n",
    "        self.fc5 = nn.Linear(32, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.first_relu(x)\n",
    "        x = self.fc2(x)\n",
    "        for i, l in enumerate(self.fc3):\n",
    "            x = l(x)\n",
    "        x = self.fc4['fc4-1'](x)\n",
    "        x = self.fc4['relu'](x)\n",
    "        y_hat = self.fc5(x)\n",
    "        return y_hat\n",
    "\n",
    "base_model = DeepFCN(225, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ae891c",
   "metadata": {},
   "source": [
    "# 两个复制品上进行module_to_idxs规划\n",
    "此处需要model, 静态层[model.fc5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e47c1a4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-12T11:27:24.585819Z",
     "start_time": "2022-04-12T11:27:24.573784Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Linear(in_features=32, out_features=10, bias=True)]\n",
      "[Linear(in_features=32, out_features=10, bias=True)]\n"
     ]
    }
   ],
   "source": [
    "model1 = deepcopy(base_model)\n",
    "static_layers1 = []\n",
    "static_layers1.append(model1.fc5)\n",
    "print(static_layers1)\n",
    "module_to_idxs1 = tp.planner.get_ordered_module_to_idxs(model1, 0.2, nn.Linear, static_layers1, torch.randn(1,128))\n",
    "\n",
    "model2 = deepcopy(base_model)\n",
    "static_layers2 = []\n",
    "static_layers2.append(model2.fc5)\n",
    "print(static_layers2)\n",
    "module_to_idxs2 = tp.planner.get_ordered_module_to_idxs(model2, 0.3, nn.Linear, static_layers2, torch.randn(1,128))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d619ce3e",
   "metadata": {},
   "source": [
    "# 看一个局部对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b2215e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-12T11:27:24.592174Z",
     "start_time": "2022-04-12T11:27:24.589064Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[43, 14, 45, 16, 2, 31, 53, 1, 27, 6, 44, 52]\n",
      "[24, 3, 16, 33, 55, 28, 9, 12, 59, 42, 38, 32, 20, 34, 46, 25, 29, 26, 52]\n"
     ]
    }
   ],
   "source": [
    "print(module_to_idxs1[model1.fc2[0]])\n",
    "\n",
    "print(module_to_idxs2[model2.fc2[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19dd7fff",
   "metadata": {},
   "source": [
    "# 随机生成交叉互换的指示向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d74b10bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-12T11:27:24.598303Z",
     "start_time": "2022-04-12T11:27:24.594108Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 5\n",
      "[0, 0, 0, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "s = random.randint(0, len(module_to_idxs1)-1)\n",
    "e = random.randint(s+1, len(module_to_idxs1))\n",
    "print(s,e)\n",
    "indicate_vector = [1 if s<=i<e else 0 for i in range(len(module_to_idxs1))]\n",
    "print(indicate_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c48c01",
   "metadata": {},
   "source": [
    "# 为了便于看效果，我们制定一个indicate_vector，不用上面随机的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2e459c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-12T11:27:24.609431Z",
     "start_time": "2022-04-12T11:27:24.602679Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24, 3, 16, 33, 55, 28, 9, 12, 59, 42, 38, 32, 20, 34, 46, 25, 29, 26, 52]\n",
      "[43, 14, 45, 16, 2, 31, 53, 1, 27, 6, 44, 52]\n"
     ]
    }
   ],
   "source": [
    "indicate_vector = [0,1,0,1,0,1]\n",
    "\n",
    "module_to_idxs1, module_to_idxs2 = tp.planner.crossover(module_to_idxs1, module_to_idxs2, indicate_vector)\n",
    "\n",
    "print(module_to_idxs1[model1.fc2[0]])\n",
    "\n",
    "print(module_to_idxs2[model2.fc2[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10e82ce",
   "metadata": {},
   "source": [
    "# 可以看出第二个全连接层的module_to_idxs已经完全交换了"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0b9d21",
   "metadata": {},
   "source": [
    "# 手动模拟遗传算法\n",
    "所依赖的输入：model本身，静态层model1.fc5.那么问题就是我如何让用户给定model model.fc5的同时，搞定model1,model1.fc5\n",
    "\n",
    "解决方案：\n",
    "用户传入model和model.fc5，还有种群大小population_size\n",
    "我们先在model.fc5上面打标签，然后再进行deepcopy，这样所有的复制品的.fc5上面都有标签 do_not_prune\n",
    "\n",
    "然后我们按照population_size进行多次复制，对每一次复制进行随机剪枝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29a71312",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-12T11:27:24.615984Z",
     "start_time": "2022-04-12T11:27:24.611783Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepFCN(\n",
      "  (fc1): Linear(in_features=225, out_features=256, bias=True)\n",
      "  (first_relu): ReLU()\n",
      "  (fc2): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (fc3): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (fc4): ModuleDict(\n",
      "    (fc4-1): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (relu): ReLU()\n",
      "  )\n",
      "  (fc5): Linear(in_features=32, out_features=10, bias=True)\n",
      ")\n",
      "89194\n"
     ]
    }
   ],
   "source": [
    "'input = model, [model.fc5], population_size'\n",
    "print(base_model)\n",
    "num_parameter_base = 0\n",
    "for para in base_model.parameters():\n",
    "    num_parameter_base += para.size().numel()\n",
    "print(num_parameter_base)\n",
    "static_layers = [base_model.fc5]\n",
    "population_size = 10\n",
    "target_type = nn.Linear\n",
    "example_inputs = torch.randn(1,225)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ac1280",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-12T05:16:33.300496Z",
     "start_time": "2022-04-12T05:16:33.293426Z"
    }
   },
   "source": [
    "维护一个模型池model_pool，这个池子里可以通过模型找到（idxs，performance）将来还可以加入categorical_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b6cb509",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-12T11:27:24.686221Z",
     "start_time": "2022-04-12T11:27:24.618379Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "for layer in static_layers:\n",
    "    layer.do_not_prune = True\n",
    "\n",
    "def get_module_to_idxs(model, amount, target_type):\n",
    "    module_to_idxs = OrderedDict()\n",
    "    def init_strategy(m):\n",
    "        strategy = tp.prune.strategy.RandomStrategy()\n",
    "        if hasattr(m, 'do_not_prune'):\n",
    "            return\n",
    "        elif isinstance(m, target_type):\n",
    "            module_to_idxs[m] = strategy(m.weight, amount=amount)\n",
    "    model.apply(init_strategy)\n",
    "    return module_to_idxs\n",
    "    \n",
    "model_pool = []\n",
    "for i in range(population_size):\n",
    "    tmp_model = deepcopy(base_model)\n",
    "    tmp_module_to_idxs = get_module_to_idxs(tmp_model, 0.2, nn.Linear)\n",
    "    tmp_model.module_to_idxs = tmp_module_to_idxs\n",
    "    DG = tp.DependencyGraph()\n",
    "    DG.build_dependency(tmp_model,example_inputs)\n",
    "    pruning_plans = []\n",
    "    def get_pruning_plans(m):\n",
    "        if m in tmp_module_to_idxs:\n",
    "            pruning_plans.append(DG.get_pruning_plan(m, tp.prune.prune_linear, idxs=tmp_module_to_idxs[m]))\n",
    "    tmp_model.apply(get_pruning_plans)\n",
    "    for plan in pruning_plans:\n",
    "        plan.exec()\n",
    "    model_pool.append(tmp_model)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c484251e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-12T11:27:24.699074Z",
     "start_time": "2022-04-12T11:27:24.688707Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DeepFCN(\n",
       "   (fc1): Linear(in_features=225, out_features=205, bias=True)\n",
       "   (first_relu): ReLU()\n",
       "   (fc2): Sequential(\n",
       "     (0): Linear(in_features=205, out_features=52, bias=True)\n",
       "     (1): ReLU()\n",
       "   )\n",
       "   (fc3): ModuleList(\n",
       "     (0): Sequential(\n",
       "       (0): Linear(in_features=52, out_features=52, bias=True)\n",
       "       (1): ReLU()\n",
       "     )\n",
       "     (1): Sequential(\n",
       "       (0): Linear(in_features=52, out_features=52, bias=True)\n",
       "       (1): ReLU()\n",
       "     )\n",
       "     (2): Sequential(\n",
       "       (0): Linear(in_features=52, out_features=52, bias=True)\n",
       "       (1): ReLU()\n",
       "     )\n",
       "   )\n",
       "   (fc4): ModuleDict(\n",
       "     (fc4-1): Linear(in_features=52, out_features=26, bias=True)\n",
       "     (relu): ReLU()\n",
       "   )\n",
       "   (fc5): Linear(in_features=26, out_features=10, bias=True)\n",
       " ),\n",
       " DeepFCN(\n",
       "   (fc1): Linear(in_features=225, out_features=205, bias=True)\n",
       "   (first_relu): ReLU()\n",
       "   (fc2): Sequential(\n",
       "     (0): Linear(in_features=205, out_features=52, bias=True)\n",
       "     (1): ReLU()\n",
       "   )\n",
       "   (fc3): ModuleList(\n",
       "     (0): Sequential(\n",
       "       (0): Linear(in_features=52, out_features=52, bias=True)\n",
       "       (1): ReLU()\n",
       "     )\n",
       "     (1): Sequential(\n",
       "       (0): Linear(in_features=52, out_features=52, bias=True)\n",
       "       (1): ReLU()\n",
       "     )\n",
       "     (2): Sequential(\n",
       "       (0): Linear(in_features=52, out_features=52, bias=True)\n",
       "       (1): ReLU()\n",
       "     )\n",
       "   )\n",
       "   (fc4): ModuleDict(\n",
       "     (fc4-1): Linear(in_features=52, out_features=26, bias=True)\n",
       "     (relu): ReLU()\n",
       "   )\n",
       "   (fc5): Linear(in_features=26, out_features=10, bias=True)\n",
       " ),\n",
       " DeepFCN(\n",
       "   (fc1): Linear(in_features=225, out_features=205, bias=True)\n",
       "   (first_relu): ReLU()\n",
       "   (fc2): Sequential(\n",
       "     (0): Linear(in_features=205, out_features=52, bias=True)\n",
       "     (1): ReLU()\n",
       "   )\n",
       "   (fc3): ModuleList(\n",
       "     (0): Sequential(\n",
       "       (0): Linear(in_features=52, out_features=52, bias=True)\n",
       "       (1): ReLU()\n",
       "     )\n",
       "     (1): Sequential(\n",
       "       (0): Linear(in_features=52, out_features=52, bias=True)\n",
       "       (1): ReLU()\n",
       "     )\n",
       "     (2): Sequential(\n",
       "       (0): Linear(in_features=52, out_features=52, bias=True)\n",
       "       (1): ReLU()\n",
       "     )\n",
       "   )\n",
       "   (fc4): ModuleDict(\n",
       "     (fc4-1): Linear(in_features=52, out_features=26, bias=True)\n",
       "     (relu): ReLU()\n",
       "   )\n",
       "   (fc5): Linear(in_features=26, out_features=10, bias=True)\n",
       " ),\n",
       " DeepFCN(\n",
       "   (fc1): Linear(in_features=225, out_features=205, bias=True)\n",
       "   (first_relu): ReLU()\n",
       "   (fc2): Sequential(\n",
       "     (0): Linear(in_features=205, out_features=52, bias=True)\n",
       "     (1): ReLU()\n",
       "   )\n",
       "   (fc3): ModuleList(\n",
       "     (0): Sequential(\n",
       "       (0): Linear(in_features=52, out_features=52, bias=True)\n",
       "       (1): ReLU()\n",
       "     )\n",
       "     (1): Sequential(\n",
       "       (0): Linear(in_features=52, out_features=52, bias=True)\n",
       "       (1): ReLU()\n",
       "     )\n",
       "     (2): Sequential(\n",
       "       (0): Linear(in_features=52, out_features=52, bias=True)\n",
       "       (1): ReLU()\n",
       "     )\n",
       "   )\n",
       "   (fc4): ModuleDict(\n",
       "     (fc4-1): Linear(in_features=52, out_features=26, bias=True)\n",
       "     (relu): ReLU()\n",
       "   )\n",
       "   (fc5): Linear(in_features=26, out_features=10, bias=True)\n",
       " ),\n",
       " DeepFCN(\n",
       "   (fc1): Linear(in_features=225, out_features=205, bias=True)\n",
       "   (first_relu): ReLU()\n",
       "   (fc2): Sequential(\n",
       "     (0): Linear(in_features=205, out_features=52, bias=True)\n",
       "     (1): ReLU()\n",
       "   )\n",
       "   (fc3): ModuleList(\n",
       "     (0): Sequential(\n",
       "       (0): Linear(in_features=52, out_features=52, bias=True)\n",
       "       (1): ReLU()\n",
       "     )\n",
       "     (1): Sequential(\n",
       "       (0): Linear(in_features=52, out_features=52, bias=True)\n",
       "       (1): ReLU()\n",
       "     )\n",
       "     (2): Sequential(\n",
       "       (0): Linear(in_features=52, out_features=52, bias=True)\n",
       "       (1): ReLU()\n",
       "     )\n",
       "   )\n",
       "   (fc4): ModuleDict(\n",
       "     (fc4-1): Linear(in_features=52, out_features=26, bias=True)\n",
       "     (relu): ReLU()\n",
       "   )\n",
       "   (fc5): Linear(in_features=26, out_features=10, bias=True)\n",
       " ),\n",
       " DeepFCN(\n",
       "   (fc1): Linear(in_features=225, out_features=205, bias=True)\n",
       "   (first_relu): ReLU()\n",
       "   (fc2): Sequential(\n",
       "     (0): Linear(in_features=205, out_features=52, bias=True)\n",
       "     (1): ReLU()\n",
       "   )\n",
       "   (fc3): ModuleList(\n",
       "     (0): Sequential(\n",
       "       (0): Linear(in_features=52, out_features=52, bias=True)\n",
       "       (1): ReLU()\n",
       "     )\n",
       "     (1): Sequential(\n",
       "       (0): Linear(in_features=52, out_features=52, bias=True)\n",
       "       (1): ReLU()\n",
       "     )\n",
       "     (2): Sequential(\n",
       "       (0): Linear(in_features=52, out_features=52, bias=True)\n",
       "       (1): ReLU()\n",
       "     )\n",
       "   )\n",
       "   (fc4): ModuleDict(\n",
       "     (fc4-1): Linear(in_features=52, out_features=26, bias=True)\n",
       "     (relu): ReLU()\n",
       "   )\n",
       "   (fc5): Linear(in_features=26, out_features=10, bias=True)\n",
       " ),\n",
       " DeepFCN(\n",
       "   (fc1): Linear(in_features=225, out_features=205, bias=True)\n",
       "   (first_relu): ReLU()\n",
       "   (fc2): Sequential(\n",
       "     (0): Linear(in_features=205, out_features=52, bias=True)\n",
       "     (1): ReLU()\n",
       "   )\n",
       "   (fc3): ModuleList(\n",
       "     (0): Sequential(\n",
       "       (0): Linear(in_features=52, out_features=52, bias=True)\n",
       "       (1): ReLU()\n",
       "     )\n",
       "     (1): Sequential(\n",
       "       (0): Linear(in_features=52, out_features=52, bias=True)\n",
       "       (1): ReLU()\n",
       "     )\n",
       "     (2): Sequential(\n",
       "       (0): Linear(in_features=52, out_features=52, bias=True)\n",
       "       (1): ReLU()\n",
       "     )\n",
       "   )\n",
       "   (fc4): ModuleDict(\n",
       "     (fc4-1): Linear(in_features=52, out_features=26, bias=True)\n",
       "     (relu): ReLU()\n",
       "   )\n",
       "   (fc5): Linear(in_features=26, out_features=10, bias=True)\n",
       " ),\n",
       " DeepFCN(\n",
       "   (fc1): Linear(in_features=225, out_features=205, bias=True)\n",
       "   (first_relu): ReLU()\n",
       "   (fc2): Sequential(\n",
       "     (0): Linear(in_features=205, out_features=52, bias=True)\n",
       "     (1): ReLU()\n",
       "   )\n",
       "   (fc3): ModuleList(\n",
       "     (0): Sequential(\n",
       "       (0): Linear(in_features=52, out_features=52, bias=True)\n",
       "       (1): ReLU()\n",
       "     )\n",
       "     (1): Sequential(\n",
       "       (0): Linear(in_features=52, out_features=52, bias=True)\n",
       "       (1): ReLU()\n",
       "     )\n",
       "     (2): Sequential(\n",
       "       (0): Linear(in_features=52, out_features=52, bias=True)\n",
       "       (1): ReLU()\n",
       "     )\n",
       "   )\n",
       "   (fc4): ModuleDict(\n",
       "     (fc4-1): Linear(in_features=52, out_features=26, bias=True)\n",
       "     (relu): ReLU()\n",
       "   )\n",
       "   (fc5): Linear(in_features=26, out_features=10, bias=True)\n",
       " ),\n",
       " DeepFCN(\n",
       "   (fc1): Linear(in_features=225, out_features=205, bias=True)\n",
       "   (first_relu): ReLU()\n",
       "   (fc2): Sequential(\n",
       "     (0): Linear(in_features=205, out_features=52, bias=True)\n",
       "     (1): ReLU()\n",
       "   )\n",
       "   (fc3): ModuleList(\n",
       "     (0): Sequential(\n",
       "       (0): Linear(in_features=52, out_features=52, bias=True)\n",
       "       (1): ReLU()\n",
       "     )\n",
       "     (1): Sequential(\n",
       "       (0): Linear(in_features=52, out_features=52, bias=True)\n",
       "       (1): ReLU()\n",
       "     )\n",
       "     (2): Sequential(\n",
       "       (0): Linear(in_features=52, out_features=52, bias=True)\n",
       "       (1): ReLU()\n",
       "     )\n",
       "   )\n",
       "   (fc4): ModuleDict(\n",
       "     (fc4-1): Linear(in_features=52, out_features=26, bias=True)\n",
       "     (relu): ReLU()\n",
       "   )\n",
       "   (fc5): Linear(in_features=26, out_features=10, bias=True)\n",
       " ),\n",
       " DeepFCN(\n",
       "   (fc1): Linear(in_features=225, out_features=205, bias=True)\n",
       "   (first_relu): ReLU()\n",
       "   (fc2): Sequential(\n",
       "     (0): Linear(in_features=205, out_features=52, bias=True)\n",
       "     (1): ReLU()\n",
       "   )\n",
       "   (fc3): ModuleList(\n",
       "     (0): Sequential(\n",
       "       (0): Linear(in_features=52, out_features=52, bias=True)\n",
       "       (1): ReLU()\n",
       "     )\n",
       "     (1): Sequential(\n",
       "       (0): Linear(in_features=52, out_features=52, bias=True)\n",
       "       (1): ReLU()\n",
       "     )\n",
       "     (2): Sequential(\n",
       "       (0): Linear(in_features=52, out_features=52, bias=True)\n",
       "       (1): ReLU()\n",
       "     )\n",
       "   )\n",
       "   (fc4): ModuleDict(\n",
       "     (fc4-1): Linear(in_features=52, out_features=26, bias=True)\n",
       "     (relu): ReLU()\n",
       "   )\n",
       "   (fc5): Linear(in_features=26, out_features=10, bias=True)\n",
       " )]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf84b126",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-12T11:27:24.706320Z",
     "start_time": "2022-04-12T11:27:24.702847Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26acb9e5",
   "metadata": {},
   "source": [
    "## 可以看出他们确实是两两不同的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d684edd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-12T11:27:24.712292Z",
     "start_time": "2022-04-12T11:27:24.708660Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pool[0].fc1.weight.equal(model_pool[1].fc1.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a504d8f",
   "metadata": {},
   "source": [
    "## 把训练流程搬过来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "182acb98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-12T11:27:24.903598Z",
     "start_time": "2022-04-12T11:27:24.714170Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torchvision\n",
    "\n",
    "def load_data_fashion_mnist(batch_size, resize=None, root='~/Datasets'):\n",
    "    \"\"\"Download the fashion mnist dataset and then load into memory.\"\"\"\n",
    "    trans = []\n",
    "    if resize:\n",
    "        trans.append(torchvision.transforms.Resize(size=resize))\n",
    "    trans.append(torchvision.transforms.ToTensor())\n",
    "    trans.append(torchvision.transforms.Lambda(lambda x: torch.flatten(x)))\n",
    "    transform = torchvision.transforms.Compose(trans)\n",
    "    \n",
    "    mnist_train = torchvision.datasets.FashionMNIST(root=root, train=True, download=True, transform=transform)\n",
    "    mnist_test = torchvision.datasets.FashionMNIST(root=root, train=False, download=True, transform=transform)\n",
    "\n",
    "    train_iter = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    test_iter = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "    return train_iter, test_iter\n",
    "\n",
    "\n",
    "def evaluate_accuracy(data_iter, net, device=None):\n",
    "    if device is None and isinstance(net, torch.nn.Module):\n",
    "        # 如果没指定device就使用net的device\n",
    "        device = list(net.parameters())[0].device\n",
    "    acc_sum, n = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            if isinstance(net, torch.nn.Module):\n",
    "                net.eval() # 评估模式, 这会关闭dropout\n",
    "                acc_sum += (net(X.to(device)).argmax(dim=1) == y.to(device)).float().sum().cpu().item()\n",
    "                net.train() # 改回训练模式\n",
    "            else: # 自定义的模型, 3.13节之后不会用到, 不考虑GPU\n",
    "                if('is_training' in net.__code__.co_varnames): # 如果有is_training这个参数\n",
    "                    # 将is_training设置成False\n",
    "                    acc_sum += (net(X, is_training=False).argmax(dim=1) == y).float().sum().item() \n",
    "                else:\n",
    "                    acc_sum += (net(X).argmax(dim=1) == y).float().sum().item() \n",
    "            n += y.shape[0]\n",
    "    return acc_sum / n\n",
    "\n",
    "\n",
    "def train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs):\n",
    "    incumbent_test_accuracy = 0\n",
    "    incumbent_epoch = 0\n",
    "    net = net.to(device)\n",
    "    print(\"training on \", device)\n",
    "    loss = torch.nn.CrossEntropyLoss()\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n, batch_count, start = 0.0, 0.0, 0, 0, time.time()\n",
    "        for X, y in train_iter:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y)\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            train_l_sum += l.cpu().item()\n",
    "            train_acc_sum += (y_hat.argmax(dim=1) == y).sum().cpu().item()\n",
    "            n += y.shape[0]\n",
    "            batch_count += 1\n",
    "        test_acc = evaluate_accuracy(test_iter, net)\n",
    "        if incumbent_test_accuracy < test_acc:\n",
    "            incumbent_test_accuracy = test_acc\n",
    "            incumbent_epoch = epoch\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec'\n",
    "              % (epoch + 1, train_l_sum / batch_count, train_acc_sum / n, test_acc, time.time() - start))\n",
    "    return {'incumbent_epoch': incumbent_epoch, 'incumbent_test_accuracy': incumbent_test_accuracy}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76598e75",
   "metadata": {},
   "source": [
    "## 进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4d4e4ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-12T11:30:11.742404Z",
     "start_time": "2022-04-12T11:27:24.905172Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on  cpu\n",
      "epoch 1, loss 0.9557, train acc 0.627, test acc 0.751, time 8.8 sec\n",
      "epoch 2, loss 0.5867, train acc 0.784, test acc 0.802, time 8.3 sec\n",
      "training on  cpu\n",
      "epoch 1, loss 0.9967, train acc 0.601, test acc 0.737, time 8.2 sec\n",
      "epoch 2, loss 0.6112, train acc 0.767, test acc 0.786, time 8.2 sec\n",
      "training on  cpu\n",
      "epoch 1, loss 0.9497, train acc 0.631, test acc 0.765, time 8.2 sec\n",
      "epoch 2, loss 0.5896, train acc 0.781, test acc 0.788, time 8.3 sec\n",
      "training on  cpu\n",
      "epoch 1, loss 0.9874, train acc 0.606, test acc 0.755, time 8.2 sec\n",
      "epoch 2, loss 0.6065, train acc 0.777, test acc 0.794, time 8.3 sec\n",
      "training on  cpu\n",
      "epoch 1, loss 1.0041, train acc 0.605, test acc 0.728, time 8.2 sec\n",
      "epoch 2, loss 0.6177, train acc 0.774, test acc 0.779, time 8.3 sec\n",
      "training on  cpu\n",
      "epoch 1, loss 0.9385, train acc 0.637, test acc 0.751, time 8.3 sec\n",
      "epoch 2, loss 0.6073, train acc 0.776, test acc 0.779, time 8.7 sec\n",
      "training on  cpu\n",
      "epoch 1, loss 0.9572, train acc 0.629, test acc 0.755, time 8.2 sec\n",
      "epoch 2, loss 0.5867, train acc 0.788, test acc 0.777, time 8.4 sec\n",
      "training on  cpu\n",
      "epoch 1, loss 0.9704, train acc 0.624, test acc 0.746, time 8.2 sec\n",
      "epoch 2, loss 0.6325, train acc 0.768, test acc 0.780, time 8.3 sec\n",
      "training on  cpu\n",
      "epoch 1, loss 0.9517, train acc 0.634, test acc 0.779, time 8.2 sec\n",
      "epoch 2, loss 0.5578, train acc 0.796, test acc 0.798, time 8.4 sec\n",
      "training on  cpu\n",
      "epoch 1, loss 0.9908, train acc 0.610, test acc 0.738, time 8.2 sec\n",
      "epoch 2, loss 0.6127, train acc 0.773, test acc 0.781, time 8.3 sec\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "for model in model_pool:\n",
    "    batch_size = 128\n",
    "    train_iter, test_iter = load_data_fashion_mnist(batch_size, resize=15)\n",
    "    lr, num_epochs = 0.001, 2\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    res = train_ch5(model, train_iter, test_iter, batch_size, optimizer, device, num_epochs)\n",
    "    model.performance = res['incumbent_test_accuracy']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d91ef8f",
   "metadata": {},
   "source": [
    "## 我们看一下模型池子里的模型都有多少参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d280d43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-12T11:30:11.750173Z",
     "start_time": "2022-04-12T11:30:11.744910Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66958\n",
      "66958\n",
      "66958\n",
      "66958\n",
      "66958\n",
      "66958\n",
      "66958\n",
      "66958\n",
      "66958\n",
      "66958\n"
     ]
    }
   ],
   "source": [
    "for model in model_pool:\n",
    "    num_parameter = 0\n",
    "    for para in model.parameters():\n",
    "        num_parameter += para.size().numel()\n",
    "    print(num_parameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b783602e",
   "metadata": {},
   "source": [
    "## 以及他们的最佳performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "166449a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-12T11:30:11.755743Z",
     "start_time": "2022-04-12T11:30:11.752497Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8018\n",
      "0.7857\n",
      "0.7881\n",
      "0.7944\n",
      "0.7795\n",
      "0.7788\n",
      "0.7774\n",
      "0.78\n",
      "0.7984\n",
      "0.781\n"
     ]
    }
   ],
   "source": [
    "for model in model_pool:\n",
    "    print(model.performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5b68cd",
   "metadata": {},
   "source": [
    "## 计算模型池中模型的fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99be81a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-12T11:30:11.762547Z",
     "start_time": "2022-04-12T11:30:11.757860Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6516598560441285\n",
      "0.6355598560441285\n",
      "0.6379598560441285\n",
      "0.6442598560441285\n",
      "0.6293598560441285\n",
      "0.6286598560441286\n",
      "0.6272598560441285\n",
      "0.6298598560441285\n",
      "0.6482598560441285\n",
      "0.6308598560441285\n"
     ]
    }
   ],
   "source": [
    "for model in model_pool:\n",
    "    num_parameter = 0\n",
    "    for para in model.parameters():\n",
    "        num_parameter += para.size().numel()\n",
    "    model.fitness = model.performance - 0.2 * (num_parameter/num_parameter_base)\n",
    "    print(model.fitness)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37613690",
   "metadata": {},
   "source": [
    "## 遗传迭代\n",
    "* 保留fitness最高的\n",
    "* 循环population-1次：\n",
    "  * 摇骰子，随机到[0,s1)则从亲代中抽样\n",
    "  * 摇骰子，随机到[s1,s1+s2)则随机选择两个亲代（不能相同）进行交叉互换\n",
    "  * 摇骰子，随机到[s1+s2, 1]则随机选择一个亲代和一个纯随机模型进行局部交叉互换，保留前者的孩子（模拟突变）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7225fb12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-12T12:16:49.704283Z",
     "start_time": "2022-04-12T12:16:49.700107Z"
    }
   },
   "outputs": [],
   "source": [
    "s1 = 0.3\n",
    "s2 = 0.55\n",
    "s3 = 1-s1-s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "52c2c681",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-12T12:16:50.046928Z",
     "start_time": "2022-04-12T12:16:50.031128Z"
    }
   },
   "outputs": [],
   "source": [
    "class ModulePool():\n",
    "    def __init__(self):\n",
    "        self.pool = []\n",
    "        self.population = 10\n",
    "        self.selection_mark = [0 for i in range(self.population)]\n",
    "        self.fitness = []\n",
    "    \n",
    "    def inherit(self):\n",
    "        if len(self.fitness) < self.population:\n",
    "            for i in range(self.population):\n",
    "                self.fitness.append(self.pool[i].fitness)\n",
    "        incumbent = self.pool[0].fitness\n",
    "        incumbent_flag = 0\n",
    "        for i in range(1, self.population):\n",
    "            if self.pool[i].fitness > incumbent:\n",
    "                incumbent = self.pool[i].fitness\n",
    "                incumbent_flag = i\n",
    "        self.selection_mark[incumbent_flag] = 1\n",
    "        print('[', incumbent_flag, ']')\n",
    "        return\n",
    "    \n",
    "    def selection(self):\n",
    "        # 根据fitness进行选择，标记在selection_mark。无重复选择。\n",
    "        # 注意pool的长度是会在过程中变化的，但population不会\n",
    "        mylist = [i for i in range(self.population)]\n",
    "        weight = [0 if self.selection_mark[i]==1 else self.fitness[i] for i in range(self.population)]\n",
    "        print(weight)\n",
    "        choice = random.choices(mylist, weights=weight, k=1)[0]\n",
    "        print('[', choice, ']')\n",
    "        self.selection_mark[choice] = 1\n",
    "        return\n",
    "    \n",
    "    def crossover(self):\n",
    "        # 根据fitness进行选择, 为了选两个不一样的，决定调两次random；进行随机片段交换,保留其中较好的孩子\n",
    "        mylist = [i for i in range(self.population)]\n",
    "        weight = [self.fitness[i] for i in range(self.population)]\n",
    "        choices = random.choices(mylist, weights=weight, k=1)\n",
    "        weight[choices[0]] = 0\n",
    "        choices.extend(random.choices(mylist, weights=weight, k=1))\n",
    "        p1 = deepcopy(self.pool[choices[0]])\n",
    "        p2 = deepcopy(self.pool[choices[1]])\n",
    "#         print(choices[0],'【p1.module_to_idxs.items()】', p1.module_to_idxs.items())\n",
    "#         print(choices[1],'【p2.module_to_idxs.items()】', p2.module_to_idxs.items()) \n",
    "        s = random.randint(0, len(p1.module_to_idxs)-1)\n",
    "        e = random.randint(s+1, len(p1.module_to_idxs))\n",
    "        indicate_vector = [1 if s<=i<e else 0 for i in range(len(module_to_idxs1))]\n",
    "#         print('indicae_vector', indicate_vector)\n",
    "        \n",
    "        for i, ((k1, v1), (k2, v2)) in enumerate(zip(*[p1.module_to_idxs.items(), p2.module_to_idxs.items()])):\n",
    "            if indicate_vector[i] == 1:\n",
    "                tmp = p1.module_to_idxs[k1]\n",
    "                p1.module_to_idxs[k1] = p2.module_to_idxs[k2]\n",
    "                p2.module_to_idxs[k2] = tmp\n",
    "#         # 对比用\n",
    "#         p1 = self.pool[choices[0]]\n",
    "#         p2 = self.pool[choices[1]]\n",
    "#         print('【p1.module_to_idxs.items()】', p1.module_to_idxs.items())\n",
    "#         print('【p2.module_to_idxs.items()】', p2.module_to_idxs.items()) \n",
    "        child1 = deepcopy(base_model)\n",
    "        child1.module_to_idxs = get_module_to_idxs(child1, 0.2, nn.Linear)\n",
    "        for i, ((k1, v1), (k2, v2)) in enumerate(zip(*[p1.module_to_idxs.items(), child1.module_to_idxs.items()])):\n",
    "                child1.module_to_idxs[k2] = p1.module_to_idxs[k1]\n",
    "        DG1 = tp.DependencyGraph()\n",
    "        DG1.build_dependency(child1,example_inputs)\n",
    "        pruning_plans1 = []\n",
    "        def get_pruning_plans(m):\n",
    "            if m in child1.module_to_idxs:\n",
    "                pruning_plans1.append(DG1.get_pruning_plan(m, tp.prune.prune_linear, idxs=child1.module_to_idxs[m]))\n",
    "        child1.apply(get_pruning_plans)\n",
    "        for plan in pruning_plans1:\n",
    "            plan.exec()\n",
    "            \n",
    "        \n",
    "        self.pool.append(child1)\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def mutation(self):\n",
    "        # 根据fitness进行选择，选一个，另一个则产生一个随机模型，进行片段交换，保留其中较好的孩子\n",
    "        return\n",
    "    \n",
    "    def age(self):\n",
    "        # 吧没有被标记的模型从pool中删除，把新模型加上\n",
    "        return\n",
    "    \n",
    "mypool = ModulePool()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "da828620",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-12T12:16:50.271711Z",
     "start_time": "2022-04-12T12:16:50.268713Z"
    }
   },
   "outputs": [],
   "source": [
    "mypool.pool = model_pool\n",
    "mypool.population = population_size\n",
    "mypool.selection_mark = [0 for i in range(mypool.population)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691c5fb4",
   "metadata": {},
   "source": [
    "## 进行一次更新迭代（mypool尚未完善）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "099885d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-12T12:16:50.659656Z",
     "start_time": "2022-04-12T12:16:50.652958Z"
    }
   },
   "outputs": [],
   "source": [
    "def evolve(mypool:ModulePool):\n",
    "    for i in range(population_size):\n",
    "        if i == 0:\n",
    "            print(i, 'inherit')\n",
    "            mypool.inherit()\n",
    "            continue\n",
    "        dice = random.random()\n",
    "        if dice < s1:\n",
    "            print(i, 'selection')\n",
    "            mypool.selection()\n",
    "        elif dice < s1+s2:\n",
    "            print(i, 'crossover')\n",
    "            mypool.crossover()\n",
    "        else:\n",
    "            print(i, 'mutation')\n",
    "            mypool.mutation()\n",
    "    mypool.age()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a70cfce3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-12T12:16:51.558362Z",
     "start_time": "2022-04-12T12:16:51.005669Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 inherit\n",
      "[ 0 ]\n",
      "1 crossover\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "Linear(in_features=225, out_features=205, bias=True)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [42]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mevolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmypool\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [41]\u001b[0m, in \u001b[0;36mevolve\u001b[0;34m(mypool)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m dice \u001b[38;5;241m<\u001b[39m s1\u001b[38;5;241m+\u001b[39ms2:\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcrossover\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m     \u001b[43mmypool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcrossover\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmutation\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Input \u001b[0;32mIn [39]\u001b[0m, in \u001b[0;36mModulePool.crossover\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m tmp_module_to_idxs:\n\u001b[1;32m     70\u001b[0m         pruning_plans\u001b[38;5;241m.\u001b[39mappend(DG\u001b[38;5;241m.\u001b[39mget_pruning_plan(m, tp\u001b[38;5;241m.\u001b[39mprune\u001b[38;5;241m.\u001b[39mprune_linear, idxs\u001b[38;5;241m=\u001b[39mtmp_module_to_idxs[m]))\n\u001b[0;32m---> 71\u001b[0m \u001b[43mtmp_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_pruning_plans\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m plan \u001b[38;5;129;01min\u001b[39;00m pruning_plans:\n\u001b[1;32m     73\u001b[0m     plan\u001b[38;5;241m.\u001b[39mexec()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/python38/lib/python3.8/site-packages/torch/nn/modules/module.py:659\u001b[0m, in \u001b[0;36mModule.apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    621\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Applies ``fn`` recursively to every submodule (as returned by ``.children()``)\u001b[39;00m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;124;03mas well as self. Typical use includes initializing the parameters of a model\u001b[39;00m\n\u001b[1;32m    623\u001b[0m \u001b[38;5;124;03m(see also :ref:`nn-init-doc`).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    656\u001b[0m \u001b[38;5;124;03m    )\u001b[39;00m\n\u001b[1;32m    657\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    658\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 659\u001b[0m     \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    660\u001b[0m fn(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    661\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/python38/lib/python3.8/site-packages/torch/nn/modules/module.py:660\u001b[0m, in \u001b[0;36mModule.apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    658\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m    659\u001b[0m     module\u001b[38;5;241m.\u001b[39mapply(fn)\n\u001b[0;32m--> 660\u001b[0m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    661\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "Input \u001b[0;32mIn [39]\u001b[0m, in \u001b[0;36mModulePool.crossover.<locals>.get_pruning_plans\u001b[0;34m(m)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_pruning_plans\u001b[39m(m):\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m tmp_module_to_idxs:\n\u001b[0;32m---> 70\u001b[0m         pruning_plans\u001b[38;5;241m.\u001b[39mappend(\u001b[43mDG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_pruning_plan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprune\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprune_linear\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midxs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtmp_module_to_idxs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mm\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Documents/python_code/pytorch_code/AutoPrune/torch_pruning/dependency.py:415\u001b[0m, in \u001b[0;36mDependencyGraph.get_pruning_plan\u001b[0;34m(self, module, pruning_fn, idxs)\u001b[0m\n\u001b[1;32m    413\u001b[0m plan \u001b[38;5;241m=\u001b[39m PruningPlan()\n\u001b[1;32m    414\u001b[0m \u001b[38;5;66;03m#  the user pruning operation\u001b[39;00m\n\u001b[0;32m--> 415\u001b[0m root_node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule_to_node\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    416\u001b[0m plan\u001b[38;5;241m.\u001b[39madd_plan(Dependency(pruning_fn, pruning_fn, root_node), idxs)\n\u001b[1;32m    418\u001b[0m visited \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[0;31mKeyError\u001b[0m: Linear(in_features=225, out_features=205, bias=True)"
     ]
    }
   ],
   "source": [
    "evolve(mypool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df647a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a5db2434",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-12T14:51:02.322931Z",
     "start_time": "2022-04-12T14:51:02.319171Z"
    }
   },
   "outputs": [],
   "source": [
    "net = mypool.pool[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bab03105",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-12T14:52:30.717220Z",
     "start_time": "2022-04-12T14:52:30.711414Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_items([(Linear(in_features=225, out_features=205, bias=True), [121, 171, 73, 161, 249, 145, 19, 233, 162, 51, 111, 222, 172, 156, 40, 126, 199, 86, 187, 61, 232, 211, 197, 115, 13, 253, 206, 167, 119, 166, 224, 96, 20, 9, 24, 91, 59, 124, 177, 236, 3, 132, 181, 242, 141, 239, 155, 205, 109, 52, 252]), (Linear(in_features=205, out_features=52, bias=True), [4, 34, 7, 15, 6, 51, 56, 44, 1, 45, 22, 55]), (Linear(in_features=52, out_features=52, bias=True), [43, 12, 36, 60, 49, 23, 38, 17, 31, 21, 39, 22]), (Linear(in_features=52, out_features=52, bias=True), [55, 16, 62, 28, 7, 8, 58, 30, 15, 40, 27, 1]), (Linear(in_features=52, out_features=52, bias=True), [10, 35, 38, 44, 62, 13, 54, 55, 32, 48, 17, 58]), (Linear(in_features=52, out_features=26, bias=True), [17, 26, 21, 7, 15, 16])])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.module_to_idxs.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b407366",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
