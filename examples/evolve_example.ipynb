{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81cb8dd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-12T06:26:13.538588Z",
     "start_time": "2022-04-12T06:26:12.872398Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.dirname(os.path.abspath('.')))\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch_pruning as tp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08f068c",
   "metadata": {},
   "source": [
    "# 搞个复杂的网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ea959ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-12T06:26:13.552221Z",
     "start_time": "2022-04-12T06:26:13.541455Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepFCN(\n",
      "  (fc1): Linear(in_features=225, out_features=256, bias=True)\n",
      "  (first_relu): ReLU()\n",
      "  (fc2): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (fc3): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (fc4): ModuleDict(\n",
      "    (fc4-1): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (relu): ReLU()\n",
      "  )\n",
      "  (fc5): Linear(in_features=32, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class DeepFCN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(DeepFCN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 256)\n",
    "        self.add_module('first_relu', nn.ReLU())\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(256,64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc3 = nn.ModuleList(\n",
    "            [nn.Sequential(\n",
    "            nn.Linear(64,64),\n",
    "            nn.ReLU()) for i in range(3)\n",
    "            ]\n",
    "        )\n",
    "        self.fc4 = nn.ModuleDict({\n",
    "            'fc4-1': nn.Linear(64,32),\n",
    "            'relu': nn.ReLU()\n",
    "        })\n",
    "        self.fc5 = nn.Linear(32, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.first_relu(x)\n",
    "        x = self.fc2(x)\n",
    "        for i, l in enumerate(self.fc3):\n",
    "            x = l(x)\n",
    "        x = self.fc4['fc4-1'](x)\n",
    "        x = self.fc4['relu'](x)\n",
    "        y_hat = self.fc5(x)\n",
    "        return y_hat\n",
    "\n",
    "model = DeepFCN(225, 10)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ae891c",
   "metadata": {},
   "source": [
    "# 两个复制品上进行module_to_idxs规划\n",
    "此处需要model, 静态层[model.fc5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e47c1a4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-12T06:26:13.562980Z",
     "start_time": "2022-04-12T06:26:13.553708Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Linear(in_features=32, out_features=10, bias=True)]\n",
      "[Linear(in_features=32, out_features=10, bias=True)]\n"
     ]
    }
   ],
   "source": [
    "model1 = deepcopy(model)\n",
    "static_layers1 = []\n",
    "static_layers1.append(model1.fc5)\n",
    "print(static_layers1)\n",
    "module_to_idxs1 = tp.planner.get_ordered_module_to_idxs(model1, 0.2, nn.Linear, static_layers1, torch.randn(1,128))\n",
    "\n",
    "model2 = deepcopy(model)\n",
    "static_layers2 = []\n",
    "static_layers2.append(model2.fc5)\n",
    "print(static_layers2)\n",
    "module_to_idxs2 = tp.planner.get_ordered_module_to_idxs(model2, 0.3, nn.Linear, static_layers2, torch.randn(1,128))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d619ce3e",
   "metadata": {},
   "source": [
    "# 看一个局部对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b2215e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-12T06:26:13.571515Z",
     "start_time": "2022-04-12T06:26:13.566885Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[55, 43, 42, 47, 37, 19, 12, 53, 11, 14, 51, 0]\n",
      "[24, 28, 44, 51, 60, 1, 54, 26, 20, 34, 40, 22, 43, 3, 21, 36, 59, 33, 5]\n"
     ]
    }
   ],
   "source": [
    "print(module_to_idxs1[model1.fc2[0]])\n",
    "\n",
    "print(module_to_idxs2[model2.fc2[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19dd7fff",
   "metadata": {},
   "source": [
    "# 随机生成交叉互换的指示向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d74b10bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-12T06:26:13.577142Z",
     "start_time": "2022-04-12T06:26:13.573449Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 6\n",
      "[0, 0, 0, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "s = random.randint(0, len(module_to_idxs1)-1)\n",
    "e = random.randint(s+1, len(module_to_idxs1))\n",
    "print(s,e)\n",
    "indicate_vector = [1 if s<=i<e else 0 for i in range(len(module_to_idxs1))]\n",
    "print(indicate_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c48c01",
   "metadata": {},
   "source": [
    "# 为了便于看效果，我们制定一个indicate_vector，不用上面随机的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2e459c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-12T06:26:13.584471Z",
     "start_time": "2022-04-12T06:26:13.578763Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24, 28, 44, 51, 60, 1, 54, 26, 20, 34, 40, 22, 43, 3, 21, 36, 59, 33, 5]\n",
      "[55, 43, 42, 47, 37, 19, 12, 53, 11, 14, 51, 0]\n"
     ]
    }
   ],
   "source": [
    "indicate_vector = [0,1,0,1,0,1]\n",
    "\n",
    "module_to_idxs1, module_to_idxs2 = tp.planner.crossover(module_to_idxs1, module_to_idxs2, indicate_vector)\n",
    "\n",
    "print(module_to_idxs1[model1.fc2[0]])\n",
    "\n",
    "print(module_to_idxs2[model2.fc2[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10e82ce",
   "metadata": {},
   "source": [
    "# 可以看出第二个全连接层的module_to_idxs已经完全交换了"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0b9d21",
   "metadata": {},
   "source": [
    "# 手动模拟遗传算法\n",
    "所依赖的输入：model本身，静态层model1.fc5.那么问题就是我如何让用户给定model model.fc5的同时，搞定model1,model1.fc5\n",
    "\n",
    "解决方案：\n",
    "用户传入model和model.fc5，还有种群大小population_size\n",
    "我们先在model.fc5上面打标签，然后再进行deepcopy，这样所有的复制品的.fc5上面都有标签 do_not_prune\n",
    "\n",
    "然后我们按照population_size进行多次复制，对每一次复制进行随机剪枝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29a71312",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-12T06:26:13.593270Z",
     "start_time": "2022-04-12T06:26:13.588489Z"
    }
   },
   "outputs": [],
   "source": [
    "'input = model, [model.fc5], population_size'\n",
    "model\n",
    "static_layers = [model.fc5]\n",
    "population_size = 10\n",
    "target_type = nn.Linear\n",
    "example_inputs = torch.randn(1,225)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed07c460",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-12T05:16:33.300496Z",
     "start_time": "2022-04-12T05:16:33.293426Z"
    }
   },
   "source": [
    "维护一个模型池model_pool，这个池子里可以通过模型找到（idxs，performance）将来还可以加入categorical_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b6cb509",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-12T06:26:13.597647Z",
     "start_time": "2022-04-12T06:26:13.595004Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73345ef7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-12T06:26:13.659878Z",
     "start_time": "2022-04-12T06:26:13.599957Z"
    }
   },
   "outputs": [],
   "source": [
    "for layer in static_layers:\n",
    "    layer.do_not_prune = True\n",
    "\n",
    "def get_module_to_idxs(model, amount, target_type):\n",
    "    module_to_idxs = OrderedDict()\n",
    "    def init_strategy(m):\n",
    "        strategy = tp.prune.strategy.RandomStrategy()\n",
    "        if hasattr(m, 'do_not_prune'):\n",
    "            return\n",
    "        elif isinstance(m, target_type):\n",
    "            module_to_idxs[m] = strategy(m.weight, amount=amount)\n",
    "    model.apply(init_strategy)\n",
    "    return module_to_idxs\n",
    "    \n",
    "model_pool = []\n",
    "for i in range(population_size):\n",
    "    tmp_model = deepcopy(model)\n",
    "    tmp_module_to_idxs = get_module_to_idxs(tmp_model, 0.2, nn.Linear)\n",
    "    tmp_model.modult_to_idxs = tmp_module_to_idxs\n",
    "    DG = tp.DependencyGraph()\n",
    "    DG.build_dependency(tmp_model,example_inputs)\n",
    "    pruning_plans = []\n",
    "    def get_pruning_plans(m):\n",
    "        if m in tmp_module_to_idxs:\n",
    "            pruning_plans.append(DG.get_pruning_plan(m, tp.prune.prune_linear, idxs=tmp_module_to_idxs[m]))\n",
    "    tmp_model.apply(get_pruning_plans)\n",
    "    for plan in pruning_plans:\n",
    "        plan.exec()\n",
    "    model_pool.append(tmp_model)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6693d3d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-12T06:26:13.673892Z",
     "start_time": "2022-04-12T06:26:13.663914Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DeepFCN(\n",
       "   (fc1): Linear(in_features=225, out_features=205, bias=True)\n",
       "   (first_relu): ReLU()\n",
       "   (fc2): Sequential(\n",
       "     (0): Linear(in_features=205, out_features=52, bias=True)\n",
       "     (1): ReLU()\n",
       "   )\n",
       "   (fc3): ModuleList(\n",
       "     (0): Sequential(\n",
       "       (0): Linear(in_features=52, out_features=52, bias=True)\n",
       "       (1): ReLU()\n",
       "     )\n",
       "     (1): Sequential(\n",
       "       (0): Linear(in_features=52, out_features=52, bias=True)\n",
       "       (1): ReLU()\n",
       "     )\n",
       "     (2): Sequential(\n",
       "       (0): Linear(in_features=52, out_features=52, bias=True)\n",
       "       (1): ReLU()\n",
       "     )\n",
       "   )\n",
       "   (fc4): ModuleDict(\n",
       "     (fc4-1): Linear(in_features=52, out_features=26, bias=True)\n",
       "     (relu): ReLU()\n",
       "   )\n",
       "   (fc5): Linear(in_features=26, out_features=10, bias=True)\n",
       " ),\n",
       " DeepFCN(\n",
       "   (fc1): Linear(in_features=225, out_features=205, bias=True)\n",
       "   (first_relu): ReLU()\n",
       "   (fc2): Sequential(\n",
       "     (0): Linear(in_features=205, out_features=52, bias=True)\n",
       "     (1): ReLU()\n",
       "   )\n",
       "   (fc3): ModuleList(\n",
       "     (0): Sequential(\n",
       "       (0): Linear(in_features=52, out_features=52, bias=True)\n",
       "       (1): ReLU()\n",
       "     )\n",
       "     (1): Sequential(\n",
       "       (0): Linear(in_features=52, out_features=52, bias=True)\n",
       "       (1): ReLU()\n",
       "     )\n",
       "     (2): Sequential(\n",
       "       (0): Linear(in_features=52, out_features=52, bias=True)\n",
       "       (1): ReLU()\n",
       "     )\n",
       "   )\n",
       "   (fc4): ModuleDict(\n",
       "     (fc4-1): Linear(in_features=52, out_features=26, bias=True)\n",
       "     (relu): ReLU()\n",
       "   )\n",
       "   (fc5): Linear(in_features=26, out_features=10, bias=True)\n",
       " ),\n",
       " DeepFCN(\n",
       "   (fc1): Linear(in_features=225, out_features=205, bias=True)\n",
       "   (first_relu): ReLU()\n",
       "   (fc2): Sequential(\n",
       "     (0): Linear(in_features=205, out_features=52, bias=True)\n",
       "     (1): ReLU()\n",
       "   )\n",
       "   (fc3): ModuleList(\n",
       "     (0): Sequential(\n",
       "       (0): Linear(in_features=52, out_features=52, bias=True)\n",
       "       (1): ReLU()\n",
       "     )\n",
       "     (1): Sequential(\n",
       "       (0): Linear(in_features=52, out_features=52, bias=True)\n",
       "       (1): ReLU()\n",
       "     )\n",
       "     (2): Sequential(\n",
       "       (0): Linear(in_features=52, out_features=52, bias=True)\n",
       "       (1): ReLU()\n",
       "     )\n",
       "   )\n",
       "   (fc4): ModuleDict(\n",
       "     (fc4-1): Linear(in_features=52, out_features=26, bias=True)\n",
       "     (relu): ReLU()\n",
       "   )\n",
       "   (fc5): Linear(in_features=26, out_features=10, bias=True)\n",
       " ),\n",
       " DeepFCN(\n",
       "   (fc1): Linear(in_features=225, out_features=205, bias=True)\n",
       "   (first_relu): ReLU()\n",
       "   (fc2): Sequential(\n",
       "     (0): Linear(in_features=205, out_features=52, bias=True)\n",
       "     (1): ReLU()\n",
       "   )\n",
       "   (fc3): ModuleList(\n",
       "     (0): Sequential(\n",
       "       (0): Linear(in_features=52, out_features=52, bias=True)\n",
       "       (1): ReLU()\n",
       "     )\n",
       "     (1): Sequential(\n",
       "       (0): Linear(in_features=52, out_features=52, bias=True)\n",
       "       (1): ReLU()\n",
       "     )\n",
       "     (2): Sequential(\n",
       "       (0): Linear(in_features=52, out_features=52, bias=True)\n",
       "       (1): ReLU()\n",
       "     )\n",
       "   )\n",
       "   (fc4): ModuleDict(\n",
       "     (fc4-1): Linear(in_features=52, out_features=26, bias=True)\n",
       "     (relu): ReLU()\n",
       "   )\n",
       "   (fc5): Linear(in_features=26, out_features=10, bias=True)\n",
       " ),\n",
       " DeepFCN(\n",
       "   (fc1): Linear(in_features=225, out_features=205, bias=True)\n",
       "   (first_relu): ReLU()\n",
       "   (fc2): Sequential(\n",
       "     (0): Linear(in_features=205, out_features=52, bias=True)\n",
       "     (1): ReLU()\n",
       "   )\n",
       "   (fc3): ModuleList(\n",
       "     (0): Sequential(\n",
       "       (0): Linear(in_features=52, out_features=52, bias=True)\n",
       "       (1): ReLU()\n",
       "     )\n",
       "     (1): Sequential(\n",
       "       (0): Linear(in_features=52, out_features=52, bias=True)\n",
       "       (1): ReLU()\n",
       "     )\n",
       "     (2): Sequential(\n",
       "       (0): Linear(in_features=52, out_features=52, bias=True)\n",
       "       (1): ReLU()\n",
       "     )\n",
       "   )\n",
       "   (fc4): ModuleDict(\n",
       "     (fc4-1): Linear(in_features=52, out_features=26, bias=True)\n",
       "     (relu): ReLU()\n",
       "   )\n",
       "   (fc5): Linear(in_features=26, out_features=10, bias=True)\n",
       " ),\n",
       " DeepFCN(\n",
       "   (fc1): Linear(in_features=225, out_features=205, bias=True)\n",
       "   (first_relu): ReLU()\n",
       "   (fc2): Sequential(\n",
       "     (0): Linear(in_features=205, out_features=52, bias=True)\n",
       "     (1): ReLU()\n",
       "   )\n",
       "   (fc3): ModuleList(\n",
       "     (0): Sequential(\n",
       "       (0): Linear(in_features=52, out_features=52, bias=True)\n",
       "       (1): ReLU()\n",
       "     )\n",
       "     (1): Sequential(\n",
       "       (0): Linear(in_features=52, out_features=52, bias=True)\n",
       "       (1): ReLU()\n",
       "     )\n",
       "     (2): Sequential(\n",
       "       (0): Linear(in_features=52, out_features=52, bias=True)\n",
       "       (1): ReLU()\n",
       "     )\n",
       "   )\n",
       "   (fc4): ModuleDict(\n",
       "     (fc4-1): Linear(in_features=52, out_features=26, bias=True)\n",
       "     (relu): ReLU()\n",
       "   )\n",
       "   (fc5): Linear(in_features=26, out_features=10, bias=True)\n",
       " ),\n",
       " DeepFCN(\n",
       "   (fc1): Linear(in_features=225, out_features=205, bias=True)\n",
       "   (first_relu): ReLU()\n",
       "   (fc2): Sequential(\n",
       "     (0): Linear(in_features=205, out_features=52, bias=True)\n",
       "     (1): ReLU()\n",
       "   )\n",
       "   (fc3): ModuleList(\n",
       "     (0): Sequential(\n",
       "       (0): Linear(in_features=52, out_features=52, bias=True)\n",
       "       (1): ReLU()\n",
       "     )\n",
       "     (1): Sequential(\n",
       "       (0): Linear(in_features=52, out_features=52, bias=True)\n",
       "       (1): ReLU()\n",
       "     )\n",
       "     (2): Sequential(\n",
       "       (0): Linear(in_features=52, out_features=52, bias=True)\n",
       "       (1): ReLU()\n",
       "     )\n",
       "   )\n",
       "   (fc4): ModuleDict(\n",
       "     (fc4-1): Linear(in_features=52, out_features=26, bias=True)\n",
       "     (relu): ReLU()\n",
       "   )\n",
       "   (fc5): Linear(in_features=26, out_features=10, bias=True)\n",
       " ),\n",
       " DeepFCN(\n",
       "   (fc1): Linear(in_features=225, out_features=205, bias=True)\n",
       "   (first_relu): ReLU()\n",
       "   (fc2): Sequential(\n",
       "     (0): Linear(in_features=205, out_features=52, bias=True)\n",
       "     (1): ReLU()\n",
       "   )\n",
       "   (fc3): ModuleList(\n",
       "     (0): Sequential(\n",
       "       (0): Linear(in_features=52, out_features=52, bias=True)\n",
       "       (1): ReLU()\n",
       "     )\n",
       "     (1): Sequential(\n",
       "       (0): Linear(in_features=52, out_features=52, bias=True)\n",
       "       (1): ReLU()\n",
       "     )\n",
       "     (2): Sequential(\n",
       "       (0): Linear(in_features=52, out_features=52, bias=True)\n",
       "       (1): ReLU()\n",
       "     )\n",
       "   )\n",
       "   (fc4): ModuleDict(\n",
       "     (fc4-1): Linear(in_features=52, out_features=26, bias=True)\n",
       "     (relu): ReLU()\n",
       "   )\n",
       "   (fc5): Linear(in_features=26, out_features=10, bias=True)\n",
       " ),\n",
       " DeepFCN(\n",
       "   (fc1): Linear(in_features=225, out_features=205, bias=True)\n",
       "   (first_relu): ReLU()\n",
       "   (fc2): Sequential(\n",
       "     (0): Linear(in_features=205, out_features=52, bias=True)\n",
       "     (1): ReLU()\n",
       "   )\n",
       "   (fc3): ModuleList(\n",
       "     (0): Sequential(\n",
       "       (0): Linear(in_features=52, out_features=52, bias=True)\n",
       "       (1): ReLU()\n",
       "     )\n",
       "     (1): Sequential(\n",
       "       (0): Linear(in_features=52, out_features=52, bias=True)\n",
       "       (1): ReLU()\n",
       "     )\n",
       "     (2): Sequential(\n",
       "       (0): Linear(in_features=52, out_features=52, bias=True)\n",
       "       (1): ReLU()\n",
       "     )\n",
       "   )\n",
       "   (fc4): ModuleDict(\n",
       "     (fc4-1): Linear(in_features=52, out_features=26, bias=True)\n",
       "     (relu): ReLU()\n",
       "   )\n",
       "   (fc5): Linear(in_features=26, out_features=10, bias=True)\n",
       " ),\n",
       " DeepFCN(\n",
       "   (fc1): Linear(in_features=225, out_features=205, bias=True)\n",
       "   (first_relu): ReLU()\n",
       "   (fc2): Sequential(\n",
       "     (0): Linear(in_features=205, out_features=52, bias=True)\n",
       "     (1): ReLU()\n",
       "   )\n",
       "   (fc3): ModuleList(\n",
       "     (0): Sequential(\n",
       "       (0): Linear(in_features=52, out_features=52, bias=True)\n",
       "       (1): ReLU()\n",
       "     )\n",
       "     (1): Sequential(\n",
       "       (0): Linear(in_features=52, out_features=52, bias=True)\n",
       "       (1): ReLU()\n",
       "     )\n",
       "     (2): Sequential(\n",
       "       (0): Linear(in_features=52, out_features=52, bias=True)\n",
       "       (1): ReLU()\n",
       "     )\n",
       "   )\n",
       "   (fc4): ModuleDict(\n",
       "     (fc4-1): Linear(in_features=52, out_features=26, bias=True)\n",
       "     (relu): ReLU()\n",
       "   )\n",
       "   (fc5): Linear(in_features=26, out_features=10, bias=True)\n",
       " )]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef3751b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-12T08:09:53.546993Z",
     "start_time": "2022-04-12T08:09:53.540148Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e27058",
   "metadata": {},
   "source": [
    "## 可以看出他们确实是两两不同的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45d3b094",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-12T06:26:13.680209Z",
     "start_time": "2022-04-12T06:26:13.675544Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pool[0].fc1.weight.equal(model_pool[1].fc1.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63d8745",
   "metadata": {},
   "source": [
    "## 把训练流程搬过来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65365840",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-12T06:26:13.779098Z",
     "start_time": "2022-04-12T06:26:13.682581Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torchvision\n",
    "\n",
    "def load_data_fashion_mnist(batch_size, resize=None, root='~/Datasets'):\n",
    "    \"\"\"Download the fashion mnist dataset and then load into memory.\"\"\"\n",
    "    trans = []\n",
    "    if resize:\n",
    "        trans.append(torchvision.transforms.Resize(size=resize))\n",
    "    trans.append(torchvision.transforms.ToTensor())\n",
    "    trans.append(torchvision.transforms.Lambda(lambda x: torch.flatten(x)))\n",
    "    transform = torchvision.transforms.Compose(trans)\n",
    "    \n",
    "    mnist_train = torchvision.datasets.FashionMNIST(root=root, train=True, download=True, transform=transform)\n",
    "    mnist_test = torchvision.datasets.FashionMNIST(root=root, train=False, download=True, transform=transform)\n",
    "\n",
    "    train_iter = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    test_iter = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "    return train_iter, test_iter\n",
    "\n",
    "\n",
    "def evaluate_accuracy(data_iter, net, device=None):\n",
    "    if device is None and isinstance(net, torch.nn.Module):\n",
    "        # 如果没指定device就使用net的device\n",
    "        device = list(net.parameters())[0].device\n",
    "    acc_sum, n = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            if isinstance(net, torch.nn.Module):\n",
    "                net.eval() # 评估模式, 这会关闭dropout\n",
    "                acc_sum += (net(X.to(device)).argmax(dim=1) == y.to(device)).float().sum().cpu().item()\n",
    "                net.train() # 改回训练模式\n",
    "            else: # 自定义的模型, 3.13节之后不会用到, 不考虑GPU\n",
    "                if('is_training' in net.__code__.co_varnames): # 如果有is_training这个参数\n",
    "                    # 将is_training设置成False\n",
    "                    acc_sum += (net(X, is_training=False).argmax(dim=1) == y).float().sum().item() \n",
    "                else:\n",
    "                    acc_sum += (net(X).argmax(dim=1) == y).float().sum().item() \n",
    "            n += y.shape[0]\n",
    "    return acc_sum / n\n",
    "\n",
    "\n",
    "def train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs):\n",
    "    incumbent_test_accuracy = 0\n",
    "    incumbent_epoch = 0\n",
    "    net = net.to(device)\n",
    "    print(\"training on \", device)\n",
    "    loss = torch.nn.CrossEntropyLoss()\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n, batch_count, start = 0.0, 0.0, 0, 0, time.time()\n",
    "        for X, y in train_iter:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y)\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            train_l_sum += l.cpu().item()\n",
    "            train_acc_sum += (y_hat.argmax(dim=1) == y).sum().cpu().item()\n",
    "            n += y.shape[0]\n",
    "            batch_count += 1\n",
    "        test_acc = evaluate_accuracy(test_iter, net)\n",
    "        if incumbent_test_accuracy < test_acc:\n",
    "            incumbent_test_accuracy = test_acc\n",
    "            incumbent_epoch = epoch\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec'\n",
    "              % (epoch + 1, train_l_sum / batch_count, train_acc_sum / n, test_acc, time.time() - start))\n",
    "    return {'incumbent_epoch': incumbent_epoch, 'incumbent_test_accuracy': incumbent_test_accuracy}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7bbe6d19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-12T06:40:38.843327Z",
     "start_time": "2022-04-12T06:26:13.781077Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on  cpu\n",
      "epoch 1, loss 1.0456, train acc 0.581, test acc 0.719, time 8.4 sec\n",
      "epoch 2, loss 0.6206, train acc 0.776, test acc 0.789, time 8.2 sec\n",
      "epoch 3, loss 0.5306, train acc 0.812, test acc 0.818, time 8.3 sec\n",
      "epoch 4, loss 0.4754, train acc 0.831, test acc 0.831, time 8.2 sec\n",
      "epoch 5, loss 0.4373, train acc 0.845, test acc 0.840, time 8.7 sec\n",
      "epoch 6, loss 0.4122, train acc 0.852, test acc 0.835, time 9.1 sec\n",
      "epoch 7, loss 0.3928, train acc 0.857, test acc 0.851, time 8.6 sec\n",
      "epoch 8, loss 0.3730, train acc 0.864, test acc 0.854, time 8.7 sec\n",
      "epoch 9, loss 0.3647, train acc 0.867, test acc 0.856, time 8.6 sec\n",
      "epoch 10, loss 0.3557, train acc 0.871, test acc 0.840, time 8.6 sec\n",
      "training on  cpu\n",
      "epoch 1, loss 1.0674, train acc 0.562, test acc 0.688, time 8.6 sec\n",
      "epoch 2, loss 0.6362, train acc 0.764, test acc 0.796, time 8.7 sec\n",
      "epoch 3, loss 0.5237, train acc 0.813, test acc 0.816, time 8.7 sec\n",
      "epoch 4, loss 0.4797, train acc 0.829, test acc 0.825, time 8.6 sec\n",
      "epoch 5, loss 0.4458, train acc 0.840, test acc 0.829, time 8.7 sec\n",
      "epoch 6, loss 0.4176, train acc 0.848, test acc 0.848, time 8.7 sec\n",
      "epoch 7, loss 0.3985, train acc 0.855, test acc 0.844, time 8.6 sec\n",
      "epoch 8, loss 0.3839, train acc 0.860, test acc 0.852, time 8.7 sec\n",
      "epoch 9, loss 0.3699, train acc 0.865, test acc 0.847, time 8.6 sec\n",
      "epoch 10, loss 0.3605, train acc 0.868, test acc 0.859, time 8.7 sec\n",
      "training on  cpu\n",
      "epoch 1, loss 0.9765, train acc 0.617, test acc 0.726, time 8.7 sec\n",
      "epoch 2, loss 0.6110, train acc 0.775, test acc 0.794, time 8.6 sec\n",
      "epoch 3, loss 0.5028, train acc 0.818, test acc 0.818, time 8.7 sec\n",
      "epoch 4, loss 0.4480, train acc 0.839, test acc 0.838, time 8.6 sec\n",
      "epoch 5, loss 0.4177, train acc 0.851, test acc 0.845, time 8.7 sec\n",
      "epoch 6, loss 0.3892, train acc 0.859, test acc 0.846, time 8.8 sec\n",
      "epoch 7, loss 0.3735, train acc 0.866, test acc 0.863, time 8.7 sec\n",
      "epoch 8, loss 0.3595, train acc 0.870, test acc 0.847, time 8.7 sec\n",
      "epoch 9, loss 0.3501, train acc 0.872, test acc 0.866, time 8.7 sec\n",
      "epoch 10, loss 0.3420, train acc 0.876, test acc 0.866, time 8.8 sec\n",
      "training on  cpu\n",
      "epoch 1, loss 1.0547, train acc 0.570, test acc 0.646, time 8.6 sec\n",
      "epoch 2, loss 0.6863, train acc 0.749, test acc 0.784, time 8.6 sec\n",
      "epoch 3, loss 0.5416, train acc 0.807, test acc 0.815, time 8.7 sec\n",
      "epoch 4, loss 0.4742, train acc 0.831, test acc 0.829, time 8.6 sec\n",
      "epoch 5, loss 0.4390, train acc 0.844, test acc 0.828, time 8.7 sec\n",
      "epoch 6, loss 0.4082, train acc 0.852, test acc 0.842, time 8.7 sec\n",
      "epoch 7, loss 0.3892, train acc 0.857, test acc 0.844, time 8.7 sec\n",
      "epoch 8, loss 0.3714, train acc 0.864, test acc 0.857, time 8.7 sec\n",
      "epoch 9, loss 0.3595, train acc 0.869, test acc 0.853, time 8.7 sec\n",
      "epoch 10, loss 0.3525, train acc 0.871, test acc 0.858, time 8.7 sec\n",
      "training on  cpu\n",
      "epoch 1, loss 1.0005, train acc 0.601, test acc 0.745, time 8.8 sec\n",
      "epoch 2, loss 0.6162, train acc 0.773, test acc 0.799, time 8.6 sec\n",
      "epoch 3, loss 0.5223, train acc 0.815, test acc 0.812, time 8.7 sec\n",
      "epoch 4, loss 0.4750, train acc 0.830, test acc 0.824, time 8.7 sec\n",
      "epoch 5, loss 0.4434, train acc 0.841, test acc 0.836, time 8.6 sec\n",
      "epoch 6, loss 0.4100, train acc 0.852, test acc 0.836, time 8.6 sec\n",
      "epoch 7, loss 0.3933, train acc 0.857, test acc 0.842, time 8.6 sec\n",
      "epoch 8, loss 0.3751, train acc 0.864, test acc 0.850, time 8.7 sec\n",
      "epoch 9, loss 0.3636, train acc 0.867, test acc 0.849, time 8.6 sec\n",
      "epoch 10, loss 0.3526, train acc 0.872, test acc 0.846, time 8.6 sec\n",
      "training on  cpu\n",
      "epoch 1, loss 0.9930, train acc 0.616, test acc 0.752, time 8.6 sec\n",
      "epoch 2, loss 0.6052, train acc 0.777, test acc 0.771, time 8.6 sec\n",
      "epoch 3, loss 0.5238, train acc 0.809, test acc 0.792, time 8.6 sec\n",
      "epoch 4, loss 0.4704, train acc 0.833, test acc 0.813, time 8.7 sec\n",
      "epoch 5, loss 0.4299, train acc 0.846, test acc 0.845, time 8.6 sec\n",
      "epoch 6, loss 0.4043, train acc 0.853, test acc 0.850, time 8.7 sec\n",
      "epoch 7, loss 0.3799, train acc 0.861, test acc 0.861, time 8.6 sec\n",
      "epoch 8, loss 0.3670, train acc 0.866, test acc 0.856, time 8.7 sec\n",
      "epoch 9, loss 0.3572, train acc 0.869, test acc 0.855, time 8.6 sec\n",
      "epoch 10, loss 0.3442, train acc 0.876, test acc 0.858, time 8.6 sec\n",
      "training on  cpu\n",
      "epoch 1, loss 1.0909, train acc 0.546, test acc 0.700, time 8.7 sec\n",
      "epoch 2, loss 0.6905, train acc 0.741, test acc 0.784, time 8.7 sec\n",
      "epoch 3, loss 0.5439, train acc 0.806, test acc 0.804, time 8.7 sec\n",
      "epoch 4, loss 0.4916, train acc 0.825, test acc 0.808, time 8.7 sec\n",
      "epoch 5, loss 0.4625, train acc 0.834, test acc 0.833, time 8.6 sec\n",
      "epoch 6, loss 0.4323, train acc 0.846, test acc 0.835, time 8.7 sec\n",
      "epoch 7, loss 0.4087, train acc 0.854, test acc 0.834, time 8.6 sec\n",
      "epoch 8, loss 0.3943, train acc 0.858, test acc 0.848, time 8.6 sec\n",
      "epoch 9, loss 0.3800, train acc 0.864, test acc 0.856, time 8.7 sec\n",
      "epoch 10, loss 0.3669, train acc 0.868, test acc 0.858, time 8.6 sec\n",
      "training on  cpu\n",
      "epoch 1, loss 0.9767, train acc 0.621, test acc 0.733, time 8.6 sec\n",
      "epoch 2, loss 0.6006, train acc 0.789, test acc 0.814, time 8.6 sec\n",
      "epoch 3, loss 0.4822, train acc 0.829, test acc 0.818, time 8.7 sec\n",
      "epoch 4, loss 0.4339, train acc 0.845, test acc 0.816, time 8.7 sec\n",
      "epoch 5, loss 0.4065, train acc 0.853, test acc 0.849, time 8.6 sec\n",
      "epoch 6, loss 0.3812, train acc 0.861, test acc 0.852, time 8.7 sec\n",
      "epoch 7, loss 0.3671, train acc 0.866, test acc 0.852, time 8.6 sec\n",
      "epoch 8, loss 0.3558, train acc 0.869, test acc 0.860, time 8.7 sec\n",
      "epoch 9, loss 0.3469, train acc 0.873, test acc 0.861, time 8.7 sec\n",
      "epoch 10, loss 0.3381, train acc 0.876, test acc 0.867, time 8.6 sec\n",
      "training on  cpu\n",
      "epoch 1, loss 0.9285, train acc 0.639, test acc 0.755, time 8.7 sec\n",
      "epoch 2, loss 0.6041, train acc 0.772, test acc 0.779, time 8.6 sec\n",
      "epoch 3, loss 0.5367, train acc 0.799, test acc 0.799, time 8.6 sec\n",
      "epoch 4, loss 0.5045, train acc 0.812, test acc 0.798, time 8.7 sec\n",
      "epoch 5, loss 0.4730, train acc 0.825, test acc 0.820, time 8.6 sec\n",
      "epoch 6, loss 0.4446, train acc 0.836, test acc 0.835, time 8.7 sec\n",
      "epoch 7, loss 0.4197, train acc 0.848, test acc 0.836, time 8.6 sec\n",
      "epoch 8, loss 0.4042, train acc 0.854, test acc 0.847, time 8.6 sec\n",
      "epoch 9, loss 0.3850, train acc 0.860, test acc 0.846, time 8.7 sec\n",
      "epoch 10, loss 0.3732, train acc 0.865, test acc 0.845, time 8.6 sec\n",
      "training on  cpu\n",
      "epoch 1, loss 1.0143, train acc 0.602, test acc 0.712, time 8.6 sec\n",
      "epoch 2, loss 0.6703, train acc 0.752, test acc 0.764, time 8.7 sec\n",
      "epoch 3, loss 0.5637, train acc 0.798, test acc 0.799, time 8.6 sec\n",
      "epoch 4, loss 0.4966, train acc 0.821, test acc 0.816, time 8.7 sec\n",
      "epoch 5, loss 0.4540, train acc 0.838, test acc 0.837, time 8.6 sec\n",
      "epoch 6, loss 0.4226, train acc 0.848, test acc 0.845, time 8.7 sec\n",
      "epoch 7, loss 0.3939, train acc 0.857, test acc 0.845, time 8.7 sec\n",
      "epoch 8, loss 0.3699, train acc 0.865, test acc 0.857, time 8.6 sec\n",
      "epoch 9, loss 0.3592, train acc 0.868, test acc 0.861, time 8.6 sec\n",
      "epoch 10, loss 0.3475, train acc 0.873, test acc 0.860, time 8.6 sec\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "for model in model_pool:\n",
    "    batch_size = 128\n",
    "    train_iter, test_iter = load_data_fashion_mnist(batch_size, resize=15)\n",
    "    lr, num_epochs = 0.001, 10\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    res = train_ch5(model, train_iter, test_iter, batch_size, optimizer, device, num_epochs)\n",
    "    model.performance = res['incumbent_test_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8636f5ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-12T08:16:22.920527Z",
     "start_time": "2022-04-12T08:16:22.914966Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8562\n",
      "0.8589\n",
      "0.8657\n",
      "0.858\n",
      "0.8501\n",
      "0.8605\n",
      "0.8579\n",
      "0.8668\n",
      "0.8472\n",
      "0.8611\n"
     ]
    }
   ],
   "source": [
    "for model in model_pool:\n",
    "    print(model.performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc65e8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
